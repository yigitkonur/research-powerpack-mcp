# Research Powerpack MCP Server - Tool Configuration
# Single source of truth for all tool metadata, descriptions, and parameter schemas
# Version: 1.0

version: "1.0"

metadata:
  name: "research-powerpack-mcp"
  description: "Research tools for AI assistants"

tools:
  # ============================================================================
  # REDDIT TOOLS
  # ============================================================================

  - name: search_reddit
    category: reddit
    capability: search
    description: |
      **Comprehensive Reddit research via Google (10 results/query, 10-50 queries supported).**

      MUST call get_reddit_post after to fetch full post content and comments.

      **QUERY REQUIREMENTS:**
      - **Minimum:** 3 queries (hard limit)
      - **Recommended:** 10+ queries (for meaningful consensus analysis)
      - **Optimal:** 20-30 queries covering all angles of the topic
      - **Maximum:** 50 queries (for comprehensive deep research)

      **OUTPUT FORMAT:**
      1. **High-Consensus Posts** - Posts appearing in multiple queries (ranked by CTR score)
      2. **All Results (CTR-Ranked)** - Aggregated unique posts sorted by weighted score
      3. **Per-Query Raw Results** - Complete results for each individual query before aggregation

      **QUERY CRAFTING STRATEGY (aim for 10-50 distinct queries):**
      - Direct topic variations (3-5 queries)
      - Recommendation/best-of queries (3-5 queries)
      - Specific tool/project names (5-10 queries)
      - Comparison queries (3-5 queries)
      - Alternative/replacement queries (3-5 queries)
      - Subreddit-specific queries (5-10 queries)
      - Problem/issue queries (3-5 queries)
      - Year-specific queries for recency (2-3 queries)

      **OPERATORS:** intitle:, "exact phrase", OR, -exclude. Auto-adds site:reddit.com.

    parameters:
      queries:
        type: array
        required: true
        items:
          type: string
        validation:
          minItems: 3
          maxItems: 50
        description: |
          **3-50 queries for Reddit research.** Minimum 3 required, but generate at least 10 for meaningful consensus. More queries = better consensus detection.

          **QUERY CATEGORIES (aim for coverage across all):**

          1. **Direct Topic (3-5):** "YouTube Music Mac app", "YTM desktop application"
          2. **Recommendations (3-5):** "best YouTube Music client Mac", "recommended YTM app"
          3. **Specific Tools (5-10):** "YTMDesktop Mac", "th-ch youtube-music", "steve228uk YT Music"
          4. **Comparisons (3-5):** "YouTube Music vs Spotify Mac", "YTM vs Apple Music desktop"
          5. **Alternatives (3-5):** "YouTube Music Mac alternative", "YTM replacement app"
          6. **Subreddits (5-10):** "r/YoutubeMusic desktop", "r/macapps YouTube Music", "r/opensource YTM"
          7. **Problems/Issues (3-5):** "YouTube Music desktop performance", "YTM app crashes Mac"
          8. **Year-Specific (2-3):** "best YouTube Music app 2024", "YTM desktop 2025"
          9. **Features (3-5):** "YouTube Music offline Mac", "YTM lyrics desktop"
          10. **Developer/GitHub (3-5):** "youtube-music electron app", "YTM github project"

      date_after:
        type: string
        required: false
        description: "Filter results after date (YYYY-MM-DD). Optional."

  - name: get_reddit_post
    category: reddit
    capability: reddit
    description: |
      **Fetch Reddit posts with smart comment allocation (2-50 posts supported).**

      **SMART COMMENT BUDGET:** 1,000 comments distributed across all posts automatically.
      - 2 posts: ~500 comments/post (deep dive)
      - 10 posts: 100 comments/post
      - 50 posts: 20 comments/post (quick scan)

      **PARAMETERS:**
      - `urls`: 2-50 Reddit post URLs. More posts = broader community perspective.
      - `fetch_comments`: Set to false for post-only queries (faster). Default: true.
      - `max_comments`: Override auto-allocation if needed.

      **USE:** After search_reddit. Maximize post count for research breadth. Comment allocation is automatic and optimized.

    parameters:
      urls:
        type: array
        required: true
        items:
          type: string
        validation:
          minItems: 2
          maxItems: 50
        description: "Reddit URLs (2-50). More posts = broader community perspective."

      fetch_comments:
        type: boolean
        required: false
        default: true
        description: "Fetch comments? Set false for quick post overview. Default: true"

      max_comments:
        type: number
        required: false
        default: 100
        description: "Override auto-allocation. Leave empty for smart allocation."

  # ============================================================================
  # DEEP RESEARCH TOOL
  # ============================================================================

  - name: deep_research
    category: research
    capability: deepResearch
    # Complex schema - use existing Zod schema, descriptions injected from YAML
    useZodSchema: true
    zodSchemaRef: "deepResearchParamsSchema"
    description: |
      **Batch deep research (2-10 questions) with dynamic token allocation.**

      **TOKEN BUDGET:** 32,000 tokens distributed across all questions:
      - 2 questions: 16,000 tokens/question (deep dive)
      - 5 questions: 6,400 tokens/question (balanced)
      - 10 questions: 3,200 tokens/question (rapid multi-topic)

      **WHEN TO USE:**
      - Need multi-perspective analysis on related topics
      - Researching a domain from multiple angles
      - Validating understanding across different aspects
      - Comparing approaches/technologies side-by-side

      **EACH QUESTION SHOULD INCLUDE:**
      - Topic & context (what decision it informs)
      - Your current understanding (to fill gaps)
      - Specific sub-questions (2-5 per topic)

      **USE:** Maximize question count for comprehensive coverage. All questions run in parallel. Group related questions for coherent research.

    # Schema descriptions to inject into existing Zod schema
    schemaDescriptions:
      questions: |
        **Batch deep research (2-10 questions) with dynamic token allocation.**

        **TOKEN BUDGET:** 32,000 tokens distributed across all questions:
        - 2 questions: 16,000 tokens/question (deep dive)
        - 5 questions: 6,400 tokens/question (balanced)
        - 10 questions: 3,200 tokens/question (rapid multi-topic)

        **WHEN TO USE:**
        - Need multi-perspective analysis on related topics
        - Researching a domain from multiple angles
        - Validating understanding across different aspects
        - Comparing approaches/technologies side-by-side

        **EACH QUESTION SHOULD INCLUDE:**
        - Topic & context (what decision it informs)
        - Your current understanding (to fill gaps)
        - Specific sub-questions (2-5 per topic)

        **USE:** Maximize question count for comprehensive coverage. All questions run in parallel. Group related questions for coherent research.

      "questions.items.question": |
        **[REQUIRED] Your research question - MUST follow this structured template:**

        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
        üìã **STRUCTURED QUESTION TEMPLATE** (You MUST use this format)
        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

        **1. üéØ WHAT I NEED:**
        [Clearly state what you're trying to achieve, solve, or understand]

        **2. ü§î WHY I'M RESEARCHING THIS:**
        [Explain the context - what decision does this inform? What problem are you solving?]

        **3. üìö WHAT I ALREADY KNOW:**
        [Share your current understanding so research fills gaps, not repeats basics]

        **4. üîß HOW I PLAN TO USE THIS:**
        [Describe the practical application - implementation, debugging, architecture, etc.]

        **5. ‚ùì SPECIFIC QUESTIONS (2-5):**
        - Question 1: [Specific, pointed question]
        - Question 2: [Another specific question]
        - Question 3: [etc.]

        **6. üåê PRIORITY SOURCES (optional):**
        [Sites/docs to prioritize: "Prefer official React docs, GitHub issues, Stack Overflow"]

        **7. ‚ö° PRIORITY INFO (optional):**
        [What matters most: "Focus on performance implications" or "Prioritize security best practices"]

      "questions.items.file_attachments": |
        **[CRITICAL FOR BUGS/CODE QUESTIONS] File attachments to include as research context.**

        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
        ‚ö†Ô∏è **YOU MUST ATTACH FILES WHEN:**
        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

        ‚úÖ **MANDATORY file attachment scenarios:**
        - üêõ **Bug investigation** ‚Üí Attach the buggy code file(s)
        - üîç **Code review** ‚Üí Attach the code to be reviewed
        - ‚ôªÔ∏è **Refactoring** ‚Üí Attach current implementation
        - üèóÔ∏è **Architecture questions about YOUR code** ‚Üí Attach relevant modules
        - ‚ö° **Performance issues** ‚Üí Attach the slow code paths
        - üîí **Security review** ‚Üí Attach the security-sensitive code
        - üß™ **Testing questions** ‚Üí Attach both the code AND test files
        - üîó **Integration issues** ‚Üí Attach files from both sides of the integration

        ‚ùå **File attachments NOT needed for:**
        - General concept questions ("What is CQRS?")
        - Technology comparisons ("React vs Vue")
        - Best practices research (unless about your specific code)
        - Documentation lookups

      "questions.items.file_attachments.items.path": |
        **[REQUIRED] Absolute file path to attach.**

        ‚ö†Ô∏è **YOU MUST USE ABSOLUTE PATHS** - e.g., "/Users/john/project/src/utils/auth.ts" NOT "src/utils/auth.ts"

        The file will be read from the filesystem and included as context for the research question. This is CRITICAL for:
        - Bug investigations (attach the failing code)
        - Code reviews (attach the code to review)
        - Refactoring questions (attach current implementation)
        - Architecture decisions (attach relevant modules)
        - Performance issues (attach the slow code path)

        **IMPORTANT:** Always use the full absolute path as shown in your IDE or terminal.

      "questions.items.file_attachments.items.start_line": |
        **[OPTIONAL] Start line number (1-indexed).**

        Use this to focus on a specific section of a large file. If omitted, reads from line 1.
        Example: start_line=50 with end_line=100 reads lines 50-100 only.

      "questions.items.file_attachments.items.end_line": |
        **[OPTIONAL] End line number (1-indexed).**

        Use this to limit the scope to relevant code sections. If omitted, reads to end of file.
        For large files (>500 lines), consider specifying a range to focus the research.

      "questions.items.file_attachments.items.description": |
        **[HIGHLY RECOMMENDED] Comprehensive description of why this file is attached and what to focus on.**

        ‚ö†Ô∏è **THIS IS CRITICAL FOR EFFECTIVE RESEARCH.** Write a detailed description explaining:

        1. **What this file is:** "This is the main authentication middleware that handles JWT validation"
        2. **Why it's relevant:** "The bug occurs when tokens expire during long-running requests"
        3. **What to focus on:** "Pay attention to the refreshToken() function on lines 45-80"
        4. **Known issues/context:** "We suspect the race condition happens in the async validation"
        5. **Related files:** "This interacts with /src/services/token-service.ts for token refresh"

  # ============================================================================
  # SCRAPE LINKS TOOL
  # ============================================================================

  - name: scrape_links
    category: scrape
    capability: scraping
    useZodSchema: true
    zodSchemaRef: "scrapeLinksParamsSchema"
    description: |
      **Universal URL content extraction (3-50 URLs) with dynamic token allocation.**

      **TOKEN ALLOCATION:** 32,000 tokens distributed across all URLs automatically.
      - 3 URLs: ~10,666 tokens/URL (deep extraction)
      - 10 URLs: 3,200 tokens/URL (detailed)
      - 50 URLs: 640 tokens/URL (high-level scan)

      **AUTOMATIC FALLBACK:** Basic ‚Üí JavaScript ‚Üí JavaScript+US geo-targeting.

      **AI EXTRACTION:** Set use_llm=true with what_to_extract for intelligent filtering. Extraction is concise + comprehensive (high info density).

      **BATCHING:** Max 30 concurrent requests. 50 URLs = [30] then [20] batches.

      **USE:** Provide 3-50 URLs. More URLs = broader coverage, fewer tokens per URL. Choose based on research scope. Maximize URL count for comprehensive research.

    schemaDescriptions:
      urls: |
        URLs to scrape (1-50). Recommend 3-5 URLs for balanced depth/breadth. More URLs = broader coverage but fewer tokens per URL. 3 URLs: ~10K tokens each (deep); 10 URLs: ~3K tokens each (balanced); 50 URLs: ~640 tokens each (scan).

      timeout: "Timeout in seconds for each URL"

      use_llm: "Enable AI processing for content extraction (requires OPENROUTER_API_KEY)"

      what_to_extract: "Specific content extraction instructions for AI. Will be enhanced with conciseness suffix automatically."

  # ============================================================================
  # WEB SEARCH TOOL
  # ============================================================================

  - name: web_search
    category: search
    capability: search
    useZodSchema: true
    zodSchemaRef: "webSearchParamsSchema"
    description: |
      **Batch web search** using Google via SERPER API. Search up to 100 keywords in parallel, get top 10 results per keyword with snippets, links, and related searches.

      **FEATURES:**
      - Supports Google search operators (site:, -exclusion, "exact phrase", filetype:)
      - Returns clickable markdown links with snippets
      - Provides related search suggestions
      - Identifies frequently appearing URLs across queries

      **USE:** For research tasks requiring multiple perspectives. Use distinct keywords to maximize coverage. Follow up with scrape_links to extract full content from promising URLs.

    schemaDescriptions:
      keywords: |
        Array of search keywords (1-100 keywords). Recommend 3-7 keywords for comprehensive research. Supports Google search operators (site:, -exclusion, "exact phrase", filetype:). More keywords = broader coverage and diverse perspectives.
